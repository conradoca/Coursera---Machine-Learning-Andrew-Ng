{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "449e6c9d",
   "metadata": {},
   "source": [
    "# Programming Exercise 4: Neural Networks Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f29a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed libraries\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralNetwork import *\n",
    "\n",
    "# Optimization module in scipy\n",
    "#from scipy import optimize\n",
    "\n",
    "# We'll use loadmap to load the matlab dataset\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4dc07366",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size  = 400  # 20x20 Input Images of Digits\n",
    "hidden_layer_size = 25   # 25 hidden units\n",
    "num_labels = 10          # 10 labels, from 0 to 9 - output layer\n",
    "\n",
    "# trying to represent the NN using an array.\n",
    "# nnDef.shape[0] = number of layers\n",
    "# nnDef[i] = number of neurons on layer i\n",
    "nnDef = np.array([input_layer_size, hidden_layer_size, num_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bbe9ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all data on a dictonary\n",
    "data = loadmat('ex4data1.mat')\n",
    "\n",
    "# Convert the data into a numpy array\n",
    "X = data['X']\n",
    "y = data['y'].flatten()\n",
    "\n",
    "# m = number of training examples\n",
    "# n = number of features\n",
    "(m,n) = X.shape\n",
    "\n",
    "# note that X has mapped \"0\" to label 10 because Matlab arrays start on 1\n",
    "# We'll normalize the 10 value back to 0, so it matches the 0 digit\n",
    "y[y == 10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2ff73864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a Theta array of arrays\n",
    "Theta = np.zeros(nnDef.size, dtype=np.ndarray)\n",
    "\n",
    "# Load the weights data to initialize Theta\n",
    "thetaMat = loadmat('ex4weights.mat')\n",
    "Theta[1] = thetaMat['Theta1']\n",
    "Theta[2] = thetaMat['Theta2']\n",
    "\n",
    "# swap first and last columns of Theta2, due to legacy from MATLAB indexing, \n",
    "# since the weight file ex3weights.mat was saved based on MATLAB indexing\n",
    "# Explanation: 0 in MATLAB is represented by 10. \n",
    "# Therefore the theta for 10 in Matlab corresponds with 0 in Python\n",
    "Theta[2] = np.roll(Theta[2], 1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7f3af506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNCOSTFUNCTION Implements the neural network cost function for the\n",
    "# neural network which performs classification\n",
    "#   J, grad = nnCostFunction(Theta, nnDef, X, y, lmbd) \n",
    "# computes the cost and gradient of the neural network\n",
    "\n",
    "def nnCostFunction(Theta, nnDef, X, y, lmbd):\n",
    "    # Useful variables\n",
    "    (m, n) = X.shape                   # m = number of training examples, n = number of features\n",
    "    num_labels = nnDef[-1]             # Output Layer units\n",
    "    num_layers = nnDef.size            # Number of layers including the Input Layer\n",
    "    \n",
    "    # a array containing the activation arrays\n",
    "    # (using numbering from 1 to be coerent with notation)\n",
    "    a = np.zeros((nnDef.size+1,), dtype=np.ndarray)\n",
    "\n",
    "    a[1] = X                # The activation for the Input layer is X\n",
    "    \n",
    "    # Extending the y vector into an array where 1 representents the label\n",
    "    y10 = np.zeros((m,num_labels))\n",
    "    y= y[:, np.newaxis]\n",
    "    for i in range(num_labels):\n",
    "        y10[:,i][:,np.newaxis] = np.where(y==i,1,0) \n",
    "    \n",
    "    # Forward Propagation\n",
    "    for i in range(1, num_layers):\n",
    "        # Add the bias unit to the a layer\n",
    "        mLayer = a[i].shape[0]\n",
    "        a[i] = np.append(np.ones((mLayer, 1)), a[i], axis=1)\n",
    "        a[i+1] = sigmoid(np.dot(a[i], Theta[i].T))\n",
    "        \n",
    "    # Cost Function\n",
    "    J = (-1/m)*np.sum((np.multiply(np.log(a[num_layers]), y10) + np.multiply((1-y10), np.log(1-a[num_layers]))))\n",
    "    # Cost adding regularization\n",
    "    for i in range(1, num_layers):\n",
    "        J = J + (lmbd/(2*m))*(np.sum((np.power(Theta[i][:, 1:], 2))))\n",
    "        \n",
    "    # Getting the gradient\n",
    "    Theta_grad = np.zeros((Theta.shape), dtype=np.ndarray)\n",
    "    delta = np.zeros((nnDef.size+1,), dtype=np.ndarray)\n",
    "    \n",
    "    delta[num_layers] = (a[num_layers] - y10)\n",
    "    for i in reversed(range(2, num_layers)):\n",
    "        delta[i] = (np.dot(Theta[i], delta[i+1]))*(a[i]*(1-a[i]))\n",
    "        delta[i] = delta[i][:, 1:]\n",
    "    \n",
    "    # Regularization part of the gradient\n",
    "    for i in reversed(range(1, num_layers)):\n",
    "        grad[i] = ((1/m)*np.dot(delta[i+1].T, a[i])) + ((lmbd/m)*np.hstack((np.zeros((Theta[i].shape[0],1)),Theta[i][:,1:])))\n",
    "    \n",
    "    return J, grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1b6807a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in reversed(range(1, num_layers)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0a9e2b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.25623899e-02, -1.05624163e-08,  2.19414684e-09, ...,\n",
       "        -1.30529929e-05, -5.04175101e-06,  2.80464449e-09],\n",
       "       [-9.83811294e-02,  7.66168682e-09, -9.75873689e-09, ...,\n",
       "        -5.60134007e-05,  2.00940969e-07,  3.54422854e-09],\n",
       "       [ 1.16156052e-01, -8.77654466e-09,  8.16037764e-09, ...,\n",
       "        -1.20951657e-04, -2.33669661e-06, -7.50668099e-09],\n",
       "       ...,\n",
       "       [-1.83220638e-01, -8.89272060e-09, -9.81968100e-09, ...,\n",
       "         2.35311186e-05, -3.25484493e-06,  9.02499060e-09],\n",
       "       [-7.02096331e-01,  3.05178374e-10,  2.56061008e-09, ...,\n",
       "        -8.61759744e-04,  9.43449909e-05,  3.83761998e-09],\n",
       "       [-3.50933229e-01,  8.85876862e-09, -6.57515140e-10, ...,\n",
       "        -1.80365926e-06, -8.14464807e-06,  8.79454531e-09]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta[1][:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339ea280",
   "metadata": {},
   "source": [
    "## Compute Cost (Feedforward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "884dc2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at parameters (loaded from ex4weights): 0.287629 \n",
      "(this value should be about 0.287629)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "J = nnCostFunction(Theta, nnDef, X, y, 0);\n",
    "\n",
    "print('Cost at parameters (loaded from ex4weights): {:.6f} \\n(this value should be about 0.287629)\\n'.format(J));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2836c",
   "metadata": {},
   "source": [
    "## Implement Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "90021f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at parameters (loaded from ex4weights): 0.383770 \n",
      "(this value should be about 0.383770)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lmbd = 1\n",
    "\n",
    "J = nnCostFunction(Theta, nnDef, X, y, lmbd);\n",
    "\n",
    "print('Cost at parameters (loaded from ex4weights): {:.6f} \\n(this value should be about 0.383770)\\n'.format(J));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a11696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
