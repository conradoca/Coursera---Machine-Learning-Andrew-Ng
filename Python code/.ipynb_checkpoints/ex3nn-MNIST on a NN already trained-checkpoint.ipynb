{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af3a080",
   "metadata": {},
   "source": [
    "# Programming Exercise 3nn: MNIST on a neural network already trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d38e8",
   "metadata": {},
   "source": [
    "In this exercise we're using an already trained NN to identify characters from the MNIST database to experiment with feedforward propagation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696a8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed libraries\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from logisticRegression import *\n",
    "# from multiClassClassification import *\n",
    "\n",
    "# Optimization module in scipy\n",
    "#from scipy import optimize\n",
    "\n",
    "# We'll use loadmap to load the matlab dataset\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afb4529",
   "metadata": {},
   "source": [
    "Defining the parameters for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef749d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size  = 400  # 20x20 Input Images of Digits\n",
    "hidden_layer_size = 25   # 25 hidden units\n",
    "num_labels = 10          # 10 labels, from 0 to 9 - output layer\n",
    "\n",
    "# trying to represent the NN using an array.\n",
    "# nnDef.shape[0] = number of layers\n",
    "# nnDef[i] = number of neurons on layer i\n",
    "nnDef = np.array([input_layer_size, hidden_layer_size, num_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee007f-f1d4-4b79-83e5-81499713fce0",
   "metadata": {},
   "source": [
    "## Loading and parsing data from a Matlab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ea7fc9-22cc-418c-a369-99dd4b2f821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all data on a dictonary\n",
    "data = loadmat('ex3data1.mat')\n",
    "\n",
    "# Convert the data into a numpy array\n",
    "X = data['X']\n",
    "y = data['y'].flatten()\n",
    "\n",
    "# m = number of training examples\n",
    "# n = number of features\n",
    "(m,n) = X.shape\n",
    "\n",
    "# note that X has mapped \"0\" to label 10 because Matlab arrays start on 1\n",
    "# We'll normalize the 10 value back to 0, so it matches the 0 digit\n",
    "y[y == 10] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59dfcf2",
   "metadata": {},
   "source": [
    "## Load the weights into variables Theta1 and Theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c8e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaMat = loadmat('ex3weights.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc19b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta1 = thetaMat['Theta1']\n",
    "Theta2 = thetaMat['Theta2']\n",
    "\n",
    "# swap first and last columns of Theta2, due to legacy from MATLAB indexing, \n",
    "# since the weight file ex3weights.mat was saved based on MATLAB indexing\n",
    "# Explanation: 0 in MATLAB is represented by 10. \n",
    "# Therefore the theta for 10 in Matlab corresponds with 0 in Python\n",
    "Theta2 = np.roll(Theta2, 1, axis=0)\n",
    "\n",
    "# We create a Theta\n",
    "Theta = np.array([Theta1, Theta2], dtype=np.ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7480aeab",
   "metadata": {},
   "source": [
    "Analizing the shape of <code>theta1</code> and <code>theta2</code> we see the coherence with the parameters defined for this exercise.\n",
    "* The Input Layer is made of 401 units (The images are 20x20 plus the bias unit = 401). The Hidden Layer is made of 25 nodes. Thus, <code>theta1</code> is (25, 401).\n",
    "* There is only one Hidden Layer. The Output Layer is made by 10 units (10 output labels) and it comes from 26 units (25 nodes from the Hidden Layer plus the bias unit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f56dd5",
   "metadata": {},
   "source": [
    "## Running feedforward propagation and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25304df8",
   "metadata": {},
   "source": [
    "We run feedforward propagation to make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c839ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prob, pred = feedForwardPropagation(Theta, X, nnDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18aa9f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Accuracy: 97.52 %\n"
     ]
    }
   ],
   "source": [
    "print('\\nTraining Set Accuracy: {:.2f} %'.format(np.mean(pred == y) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1e9cc",
   "metadata": {},
   "source": [
    "## Seeing some examples to see what's predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db65870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
